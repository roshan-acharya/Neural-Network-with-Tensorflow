{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c96ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x=tf.Variable(3, name='x')\n",
    "y=tf.Variable(4, name='y')\n",
    "f=x*x*y+y+2\n",
    "\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30adb2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "w=tf.constant(2, name='w')\n",
    "x=w+2\n",
    "y=x+5\n",
    "z=x*3\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72ff32e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.74395752e+01]\n",
      " [ 4.35960054e-01]\n",
      " [ 9.34249908e-03]\n",
      " [-1.07052356e-01]\n",
      " [ 6.46347046e-01]\n",
      " [-4.19820799e-06]\n",
      " [-3.77458939e-03]\n",
      " [-4.26262796e-01]\n",
      " [-4.40217435e-01]]\n"
     ]
    }
   ],
   "source": [
    "#training linear regression with TensorFlow\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "\n",
    "\n",
    "housing= fetch_california_housing()\n",
    "m,n=housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X=tf.constant(housing_data_plus_bias , dtype=tf.float32, name='X')\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32, name='y')\n",
    "XT=tf.transpose(X, name='XT')\n",
    "theta=tf.matmul(tf.matmul(tf.linalg.inv(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "print(theta.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b066a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 MSE: 8.654016\n",
      "Epoch: 100 MSE: 4.893134\n",
      "Epoch: 200 MSE: 4.831056\n",
      "Epoch: 300 MSE: 4.823523\n",
      "Epoch: 400 MSE: 4.8186216\n",
      "Epoch: 500 MSE: 4.8149767\n",
      "Epoch: 600 MSE: 4.8122416\n",
      "Epoch: 700 MSE: 4.8101797\n",
      "Epoch: 800 MSE: 4.808619\n",
      "Epoch: 900 MSE: 4.807431\n"
     ]
    }
   ],
   "source": [
    "#impleminting gradient descent\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(housing_data_plus_bias)\n",
    "X = tf.constant(X_scaled, dtype=tf.float32, name='X')\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "     y_pred=tf.matmul(X, theta, name='y_pred')\n",
    "     error= y_pred-y\n",
    "     mse=tf.reduce_mean(tf.square(error), name='mse')\n",
    "     gradients = 2/m * tf.matmul(tf.transpose(X), error, name='gradients')\n",
    "     training_op = theta.assign(theta - learning_rate * gradients)\n",
    "     return mse\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    mse = train_step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch:\", epoch, \"MSE:\", mse.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d0dfb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 MSE: 9.695161\n",
      "Epoch: 100 MSE: 4.998422\n",
      "Epoch: 200 MSE: 4.83737\n",
      "Epoch: 300 MSE: 4.823116\n",
      "Epoch: 400 MSE: 4.8179564\n",
      "Epoch: 500 MSE: 4.814452\n",
      "Epoch: 600 MSE: 4.811845\n",
      "Epoch: 700 MSE: 4.80988\n",
      "Epoch: 800 MSE: 4.808391\n",
      "Epoch: 900 MSE: 4.8072577\n"
     ]
    }
   ],
   "source": [
    "#implementing gradient descent with auto diff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(housing_data_plus_bias)\n",
    "X = tf.constant(X_scaled, dtype=tf.float32, name='X')\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "     y_pred=tf.matmul(X, theta, name='y_pred')\n",
    "     error= y_pred-y\n",
    "     mse=tf.reduce_mean(tf.square(error), name='mse')\n",
    "     gradients = tf.gradients(mse, [theta])[0]\n",
    "     training_op = theta.assign(theta - learning_rate * gradients)\n",
    "     return mse\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    mse = train_step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch:\", epoch, \"MSE:\", mse.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e6f3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding data to the model\n",
    "#placeholder are used too output data to the model\n",
    "#It must have rank 2 and three columns and any no of rows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b768777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 MSE: 9.526108\n",
      "Epoch: 100 MSE: 4.943314\n",
      "Epoch: 200 MSE: 4.873323\n",
      "Epoch: 300 MSE: 4.8532634\n",
      "Epoch: 400 MSE: 4.839321\n",
      "Epoch: 500 MSE: 4.829276\n",
      "Epoch: 600 MSE: 4.8220296\n",
      "Epoch: 700 MSE: 4.816802\n",
      "Epoch: 800 MSE: 4.8130307\n",
      "Epoch: 900 MSE: 4.810309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my_model/my_model.ckpt-1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(housing_data_plus_bias)\n",
    "X = tf.constant(X_scaled, dtype=tf.float32, name='X')\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "     y_pred=tf.matmul(X, theta, name='y_pred')\n",
    "     error= y_pred-y\n",
    "     mse=tf.reduce_mean(tf.square(error), name='mse')\n",
    "     gradients = tf.gradients(mse, [theta])[0]\n",
    "     training_op = theta.assign(theta - learning_rate * gradients)\n",
    "     return mse\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    mse = train_step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch:\", epoch, \"MSE:\", mse.numpy())\n",
    "\n",
    "\n",
    "ckpt=tf.train.Checkpoint(theta=theta)\n",
    "ckpt.save('my_model/my_model.ckpt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f54f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored theta: [[ 0.0768702 ]\n",
      " [ 0.29469442]\n",
      " [-0.4576459 ]\n",
      " [ 0.6468539 ]\n",
      " [ 0.6776204 ]\n",
      " [-0.42620993]\n",
      " [ 0.5068555 ]\n",
      " [ 0.02532768]\n",
      " [-0.4646113 ]]\n"
     ]
    }
   ],
   "source": [
    "theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0))\n",
    "ckpt = tf.train.Checkpoint(theta=theta)\n",
    "ckpt.restore(tf.train.latest_checkpoint('./my_model_checkpoint')).expect_partial()\n",
    "\n",
    "print(\"Restored theta:\", theta.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64277fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE: 6.836280345916748\n",
      "Epoch 100, MSE: 5.288146495819092\n",
      "Epoch 200, MSE: 5.127159595489502\n",
      "Epoch 300, MSE: 5.037325859069824\n",
      "Epoch 400, MSE: 4.973446846008301\n",
      "Epoch 500, MSE: 4.927204608917236\n",
      "Epoch 600, MSE: 4.893655300140381\n",
      "Epoch 700, MSE: 4.869289875030518\n",
      "Epoch 800, MSE: 4.851576805114746\n",
      "Epoch 900, MSE: 4.838684558868408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my_model/my_model.ckpt-1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(housing_data_plus_bias)\n",
    "X = tf.constant(X_scaled, dtype=tf.float32)\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32)\n",
    "\n",
    "theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0))\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "logdir = os.path.join(\"tf_logs\", f\"run-{now}\")\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = tf.matmul(X, theta)\n",
    "        with tf.name_scope(\"my_scope\"):\n",
    "            error = y_pred - y\n",
    "            mse = tf.reduce_mean(tf.square(error))\n",
    "    gradients = tape.gradient(mse, [theta])\n",
    "    theta.assign_sub(learning_rate * gradients[0])\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"MSE\", mse, step=epoch)\n",
    "        writer.flush()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, MSE: {mse.numpy()}\")\n",
    "\n",
    "ckpt = tf.train.Checkpoint(theta=theta)\n",
    "ckpt.save('my_model/my_model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd1e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  5\n",
      "d:  6\n"
     ]
    }
   ],
   "source": [
    "#namescope in tensorflow\n",
    "\n",
    "with tf.name_scope(\"Input\"):\n",
    "    a=tf.constant(2, name='a')\n",
    "    b=tf.constant(3, name='b')\n",
    "\n",
    "with tf.name_scope(\"Computation\"):\n",
    "    c=tf.add(a, b, name='c')\n",
    "    d=tf.multiply(a, b, name='d')\n",
    "\n",
    "print(\"c: \",c.numpy())\n",
    "print(\"d: \",d.numpy())\n",
    "writer = tf.summary.create_file_writer(\"logs/my_graph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd43688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modularity in tensorflow\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w = tf.Variable(tf.random.normal([X.shape[1], 1]), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, 0.0, name=\"relu_output\")\n",
    "\n",
    "n_features = 3\n",
    "X_input = tf.constant(np.random.rand(5, n_features), dtype=tf.float32)\n",
    "with tf.name_scope(\"Relu_Layers\"):\n",
    "    relus = [relu(X_input) for _ in range(5)]\n",
    "\n",
    "with tf.name_scope(\"Output\"):\n",
    "    output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "logdir = \"logs/relu_graph/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "@tf.function\n",
    "def run_and_log():\n",
    "    tf.summary.scalar(\"output_sum_mean\", tf.reduce_mean(output), step=0)\n",
    "\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "run_and_log()\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name=\"relu_trace\", step=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
